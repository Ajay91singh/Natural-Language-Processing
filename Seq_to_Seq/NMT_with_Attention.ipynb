{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20944585",
   "metadata": {},
   "source": [
    "Original notebook [here](https://github.com/omarsar/pytorch_neural_machine_translation_attention/blob/master/NMT_in_PyTorch.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109c1fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import unicodedata  # To install : pip install Unidecode\n",
    "import re\n",
    "import time\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284f03a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c6a74f",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227bc4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-22 17:16:49--  http://www.manythings.org/anki/spa-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.21.55.222, 172.67.173.198, 2606:4700:3031::6815:37de, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.21.55.222|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4934182 (4.7M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   4.71M  3.31MB/s    in 1.4s    \n",
      "\n",
      "2021-04-22 17:16:51 (3.31 MB/s) - ‘spa-eng.zip’ saved [4934182/4934182]\n",
      "\n",
      "Archive:  spa-eng.zip\n",
      "  inflating: _about.txt              \n",
      "  inflating: spa.txt                 \n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/spa-eng.zip\n",
    "!unzip spa-eng.zip\n",
    "!rm spa-eng.zip\n",
    "!rm _about.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "966c6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('spa.txt', encoding='UTF-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f7ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "747eea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size (smaller to reduce computation)\n",
    "num_examples = 30000\n",
    "\n",
    "# creates lists containing each pair\n",
    "original_word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cfa1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\", \"attribution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98e909a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng       es                                        attribution\n",
       "0  Go.      Ve.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1  Go.    Vete.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2  Go.    Vaya.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3  Go.  Váyase.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4  Hi.    Hola.  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f21a778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('attribution',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e322f886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng       es\n",
       "0  Go.      Ve.\n",
       "1  Go.    Vete.\n",
       "2  Go.    Vaya.\n",
       "3  Go.  Váyase.\n",
       "4  Hi.    Hola."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "204b59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    \"\"\"\n",
    "    Normalizes latin chars with accent to their canonical decomposition\n",
    "    \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588ec92",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ed4967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>&lt;start&gt; it s all yours . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; es todo tuyo . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21464</th>\n",
       "      <td>&lt;start&gt; do you like english ? &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ¿ te gusta el ingles ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24300</th>\n",
       "      <td>&lt;start&gt; tom is making faces . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; tom esta haciendo muecas . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15166</th>\n",
       "      <td>&lt;start&gt; i want to go back . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; quiero volver . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>&lt;start&gt; recess ended . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; se acabo el recreo . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19853</th>\n",
       "      <td>&lt;start&gt; think for a moment . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; piensa por un momento . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>&lt;start&gt; ignore tom . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ignora a tom . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>&lt;start&gt; tom believed mary . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; tom le creia a maria . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5927</th>\n",
       "      <td>&lt;start&gt; watch closely . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; vigila atentamente . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21327</th>\n",
       "      <td>&lt;start&gt; can i use the phone ? &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ¿ puedo usar el telefono ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       eng                                        es\n",
       "7196        <start> it s all yours . <end>              <start> es todo tuyo . <end>\n",
       "21464  <start> do you like english ? <end>      <start> ¿ te gusta el ingles ? <end>\n",
       "24300  <start> tom is making faces . <end>  <start> tom esta haciendo muecas . <end>\n",
       "15166    <start> i want to go back . <end>             <start> quiero volver . <end>\n",
       "3604          <start> recess ended . <end>        <start> se acabo el recreo . <end>\n",
       "19853   <start> think for a moment . <end>     <start> piensa por un momento . <end>\n",
       "1373            <start> ignore tom . <end>              <start> ignora a tom . <end>\n",
       "16381    <start> tom believed mary . <end>      <start> tom le creia a maria . <end>\n",
       "5927         <start> watch closely . <end>        <start> vigila atentamente . <end>\n",
       "21327  <start> can i use the phone ? <end>  <start> ¿ puedo usar el telefono ? <end>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['eng'] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
    "data['es'] = data.es.apply(lambda w: preprocess_sentence(w))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14740be",
   "metadata": {},
   "source": [
    "## Building Vocabulary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdde0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "\n",
    "class LanguageIndex:\n",
    "    def __init__(self, lang):\n",
    "        \"\"\"\n",
    "        lang are the list of phrases from each language\n",
    "        \"\"\"\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        \n",
    "        self.create_index()\n",
    "    \n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            # update with individual tokens\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "        \n",
    "        # sort the vocab\n",
    "        self.vocab = sorted(self.vocab)\n",
    "        \n",
    "        # add a padding token with index 0\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        \n",
    "        # word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1 # (+1) because of pad token\n",
    "        \n",
    "        # index to word mapping\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73854346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 9047, 3, 4],\n",
       " [5, 9166, 3, 4],\n",
       " [5, 9039, 3, 4],\n",
       " [5, 9046, 3, 4],\n",
       " [5, 4692, 3, 4],\n",
       " [5, 2279, 1, 4],\n",
       " [5, 2277, 1, 4],\n",
       " [5, 2276, 1, 4],\n",
       " [5, 2284, 1, 4],\n",
       " [5, 2284, 3, 4]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index language using the class above\n",
    "inp_lang = LanguageIndex(data[\"es\"].values.tolist())\n",
    "targ_lang = LanguageIndex(data[\"eng\"].values.tolist())\n",
    "\n",
    "# vectorize the input and target languages\n",
    "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')] for es in data[\"es\"].values.tolist()]\n",
    "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')] for eng in data[\"eng\"].values.tolist()]\n",
    "input_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28ea0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1815, 3, 4],\n",
       " [5, 1815, 3, 4],\n",
       " [5, 1815, 3, 4],\n",
       " [5, 1815, 3, 4],\n",
       " [5, 2008, 3, 4],\n",
       " [5, 3565, 1, 4],\n",
       " [5, 3565, 1, 4],\n",
       " [5, 3565, 1, 4],\n",
       " [5, 3565, 1, 4],\n",
       " [5, 3565, 3, 4]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34e6b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b22061bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the max_length of input and output tensor\n",
    "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed1ade58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x, max_len):\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    if len(x) > max_len: padded[:] = x[:max_len]\n",
    "    else: padded[:len(x)] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60358d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace padding\n",
    "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
    "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
    "len(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c945b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000, 6000, 6000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating training and validation sets using 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "#show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f31db4",
   "metadata": {},
   "source": [
    "## Load Dataset into DataLoader for Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9945b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d354c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        self.length = [np.sum(1 - np.equal(x, 0)) for x in X]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        x_len = selg.length[index]\n",
    "        return x, y, x_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a61b1e",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4afbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 63\n",
    "N_BATCH = BUFFER_SIZE // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
    "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
    "\n",
    "dataset = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                    drop_last=True,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
    "    \n",
    "    def forward(self, x, lens, device):\n",
    "        x = self.embedding(x)\n",
    "        ## complete the implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
